# Water Quality Prediction Model Report

## Group –7 Structure and Task Allocation

### Group Members
- **Kevin Nyiringango**:  Data Handler
  - Responsibilities: Load data, handle missing values and prepare the dataset for training.

- **Caroline Gyireh**: Vanilla Model Implementor
  - Responsibilities: Implement and train the baseline neural network model without regularization.

- **Elvis Guy Bakunzi**: Model Optimizer 1
  - Responsibilities: Implement L1 regularization in the model and analyze its impact on performance.

- **Fidel Chrétien Impano**: Model Optimizer 2
  - Responsibilities: Implement L2 regularization in the model and analyze its impact on performance.

- **All Members**: Error Analyst
  - Responsibilities: Conduct error analysis, compare model performances, and provide insights for improvements.

## Summary of the Implementation Process

### Data Loading
- The water quality dataset was loaded using the Pandas library.
- Missing values were handled by filling them with the mean of the respective columns.

### Data Preprocessing
- The dataset was split into feature matrix (X) and target vector (Y).
- Features were scaled using StandardScaler to standardize the input data.

### Data Splitting
- The dataset was divided into training (80%) and testing (20%) sets.

### Model Architecture
- A simple feedforward neural network was constructed using Keras.
- Three variations of the model were created:
  1. Vanilla Model (no regularization)
  2. L1 Regularization Model
  3. L2 Regularization Model

### Regularization Techniques
- L1 and L2 regularization were implemented in their respective models to prevent overfitting.

### Early Stopping
- Early stopping was applied to monitor the model’s performance during training.

### Model Training
- Each model was compiled and trained using the training data. 
- Training and validation accuracy were monitored.

### Model Evaluation
- Models were evaluated using loss and accuracy metrics on the testing set.
- Confusion matrices and classification reports were generated for deeper insights.

## Outcome of Different Variations of Implementations

### Vanilla Model
- **Loss**: 0.7812
- **Accuracy**: 0.6387
- **Observations**: [Briefly describe performance, e.g., overfitting, underfitting]

### L1 Regularization Model
- **Loss**: 0.6640
- **Accuracy**: 0.6281
- **Confusion Matrix**: 
[Insert confusion matrix]
- **Classification Report**: 
[Insert relevant metrics]
- **Observations**: [Discuss impact of L1 regularization]

### L2 Regularization Model
- **Loss**: 0.6301
- **Accuracy**: 0.6662
- **Confusion Matrix**: 
[Insert confusion matrix]
- **Classification Report**: 
[Insert relevant metrics]
- **Observations**: [Discuss impact of L2 regularization]

### Comparison of Models
- **Accuracy Comparison**: [Summarize how accuracy varied across models]
- **Loss Comparison**: [Summarize how loss varied across models]
- **Conclusion**: [Discuss which model performed best and possible reasons why]

## Future Work
- Suggestions for further improvements or variations, such as exploring different 

